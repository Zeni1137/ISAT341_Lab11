{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23066e37",
   "metadata": {},
   "source": [
    "<center>\n",
    "<font color='green'/><h1 style=\"text-align:center; color:red\"> ISAT 341: Machine Learning and Data Science with Python </h1>\n",
    "\n",
    "<font color='blue'/><h3 style=\"text-align:center; color:blue\">Lab11-Final Exam (Part II) :Implementing an Adaptive Linear Neuron and Gradient Descent in Python</h3>\n",
    "    \n",
    "<h3 style=\"text-align:center; color:blue\";>(Supervised Learning: Classification of the SciKit Learn Digits Dataset) </h3>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccebdca",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/adaline.png\" width =300; height = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd59d6e",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "* Reuse and modify code from previous labs\n",
    "* Understand and Implement Gradient Descent in Python\n",
    "* Extend the MCP and Rosenblatt Perceptron model developed in Python to include Gradient Descent\n",
    " * Implement this ADAptive LInear NEuron classifier (Adaline) and Gradient Descent in Python\n",
    "* Mathematically Extend the Perceptron Binary Model to a MultiClass Model (Numpy Linear Algebra)\n",
    "* Use the Python Programming Language to Implement Frank Rosenblattâ€™s perceptron learning rule based on the MCP neuron model.\n",
    "* Use NumPy matrix products and other Numpy features (arrays and methods) to create a subset of handwritten digits\n",
    "* Train the Adaline model for multiclass classification on subset of handwritten digits\n",
    "* Implement a Sigmoid Perceptron Class that includes Gradient Descent developed by  Generative Artificial Intelligence (GenAI) to compare and contrast to our Adaline model.\n",
    "* Use and compare the GenAI Perceptron model to the model built from scratch using  object-oriented python.\n",
    "* Create Predictive Models\n",
    "* Perform Model Evaluation\n",
    "    * Model Score and Accuracy\n",
    "    * Confusion Matrix\n",
    "* Plot the Cost (loss) Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad19fce",
   "metadata": {},
   "source": [
    "## <font color='orange'/>Class Adaline with Gradient Descent in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87e81e",
   "metadata": {},
   "source": [
    "As we indicated in Part I, the Perceptron rule and the Adaline rule are very similar. To implement the Adaline learning rule, we only need to take the Perceptron Class that we used earlier and modify the fit method so that the weights are updated by minimizing the cost function by gradient descent. The COMPLETE Python Class for implementing Adaline using gradient descent is:\n",
    "<img src=\"images/class_adaline.png\" width = 600; height = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6158f3ab",
   "metadata": {},
   "source": [
    "### <font color = 'green'/>1-TO DO : Carefully enter the code for the Python class AdalineGD in the empty cell below the heading.\n",
    "#### <font color='blue'/>Make sure you examine and understand every line of code in the AdalineGD class after you enter it below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43370e6c",
   "metadata": {},
   "source": [
    "### <font color='red'/> class Adaline: <font color='blue'/>Implementing an Adaptive Linear Neuron in Python\n",
    "#### <font color='blue'/> Minimizing cost functions with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ee54a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdalineGD(object):\\\n",
    "    \n",
    "    def __init__(self, eta=0.1, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.1, size=1 + X.shape[1])\n",
    "        \n",
    "        self.cost_ = []\n",
    "        \n",
    "        for i in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            output = self.activation(net_input)\n",
    "            errors = (y - output)\n",
    "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w_[0] += self.eta * errors.sum()\n",
    "            cost = (errors**2).sum() / 2.0\n",
    "            self.cost_.append(cost)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        '''Calculate Net Input'''\n",
    "        return np.dot(X, self.w_[1:] + self.w_[0])\n",
    "    \n",
    "    def activation(self, X):\n",
    "        '''Compute Linear activation'''\n",
    "        return X\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''Return class label after unit step'''\n",
    "        return np.where(self.activation(self.net_input(X))>= 0.0, 1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b691f660",
   "metadata": {},
   "source": [
    "<img src= \"images/converge_diverge_models.png\" width=700>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0377bc5",
   "metadata": {},
   "source": [
    "### <font color='green'/> Standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5a2736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scientific Python imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d531a1eb",
   "metadata": {},
   "source": [
    "# <font color='orange'/>Using the MNIST Dataset with the Perceptron Classification Model \n",
    "When one learns how to program, there's a tradition that the first thing you do is print \"Hello World.\" Just like programming has Hello World, machine learning has MNIST.\n",
    "\n",
    "MNIST is a simple computer vision dataset. It consists of images of handwritten digits like these:\n",
    "<center>\n",
    "    <img src=\"images/mnist_image.png\" width=250; height=200>\n",
    "</center>\n",
    "\n",
    "It also includes labels for each image, telling us which digit it is. For example, the labels for the above images are 5, 0, 4, and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69279f8",
   "metadata": {},
   "source": [
    "###  <font color='green'/> 2-TO DO: Loading Data\n",
    "Use `Pandas` to load MNIST data into a dataframe. <font color='red'/> Name the dataframe df_mnist. Also display the entire dataset in the second cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b851c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnist = pd.read_csv('mnist_datasets/mnist_784.csv',  low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8210b0",
   "metadata": {},
   "source": [
    "###### <font color='orange'/>Code to dispaly the entire data in the dataframe has been provided for you below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89995bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "69995       0       0       0       0       0       0       0       0       0   \n",
       "69996       0       0       0       0       0       0       0       0       0   \n",
       "69997       0       0       0       0       0       0       0       0       0   \n",
       "69998       0       0       0       0       0       0       0       0       0   \n",
       "69999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0            0  ...         0         0         0         0         0   \n",
       "1            0  ...         0         0         0         0         0   \n",
       "2            0  ...         0         0         0         0         0   \n",
       "3            0  ...         0         0         0         0         0   \n",
       "4            0  ...         0         0         0         0         0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "69995        0  ...         0         0         0         0         0   \n",
       "69996        0  ...         0         0         0         0         0   \n",
       "69997        0  ...         0         0         0         0         0   \n",
       "69998        0  ...         0         0         0         0         0   \n",
       "69999        0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  pixel784  class  \n",
       "0             0         0         0         0      5  \n",
       "1             0         0         0         0      0  \n",
       "2             0         0         0         0      4  \n",
       "3             0         0         0         0      1  \n",
       "4             0         0         0         0      9  \n",
       "...         ...       ...       ...       ...    ...  \n",
       "69995         0         0         0         0      2  \n",
       "69996         0         0         0         0      3  \n",
       "69997         0         0         0         0      4  \n",
       "69998         0         0         0         0      5  \n",
       "69999         0         0         0         0      6  \n",
       "\n",
       "[70000 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb71e57",
   "metadata": {},
   "source": [
    "### <font color='green'/> 3-TO DO:Print the Shape of the data\n",
    "print the shape of the data in the *dataframe* in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df88c090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(df_mnist.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bedf53b",
   "metadata": {},
   "source": [
    "There are 70,000 images and each image has 784 features (each image is 28 x 28 pixels and each pixel represents a feature of an image). Each image of the MNIST dataset is encoded in a 784 dimensional vector, representing a 28 x 28 pixel image. Each pixel has a value between 0 and 255, representing the pixel's intensity, from 0 (white) to 255 (black) corresponding to the grey-value of a pixel.\n",
    "###### <font color='red'/>make sure you understand why the shape is displaying that there are 785 columns!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1013d1bb",
   "metadata": {},
   "source": [
    "### <font color='green'/> 4-TO DO: Processing Data\n",
    "In the cell below, use Pandas `loc` to create the feature matrix and column vector. This can be done as follows to create the *feature matrix*:\n",
    "\n",
    "Since the last column in the dataset is the *class* attribute , we need to select all columns except one column in Pandas DataFrame. To do this we can use  `df.loc[:, df.columns != <column name>]` as follows:\n",
    "\n",
    "#### <font color='green'/>  Steps\n",
    "\n",
    "1)  Initialize a variable *col* with column name that you want to exclude.\n",
    "\n",
    "2)  Use `df.loc[:, df.columns != col]` to create another DataFrame excluding a particular column.\n",
    "\n",
    "3) To make sure you have extracted the columns you expect, you can print the DataFrame without `col` column.\n",
    "###### <font color='red'/>WARNING: We need these to be numpy arrays so make sure you convert them during this process. See your labs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02009bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature matrix and target vector from dataframe\n",
    "X = np.asarray(df_mnist.loc[:, df_mnist.columns != 'class'])\n",
    "y = np.asarray(df_mnist.iloc[:,-1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879e99f",
   "metadata": {},
   "source": [
    "### <font color='green'/> 5-TO DO: Simple Data Exploration for Images\n",
    "\n",
    "In the cell below print the following:\n",
    "```python\n",
    "print('This is how X[0] looks when \"flattened\" \\n{}'.format(X[0]))\n",
    "print ('\\nThis is how X[0] looks when \"reshaped\" to image format \\n{}'.format(X[0].reshape(28,28)))\n",
    "print('\\nThis is simply the target vector value that is associated with the image {}'.format(y[0]))\n",
    "```\n",
    "###### <font color='orange'/>You should take a moment and look at the output. Notice which are 1D or 2D arrays and the values they hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57df65fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is how X[0] looks when \"flattened\" \n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
      " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
      " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
      "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
      "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
      " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
      " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
      " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
      "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "This is how X[0] looks when \"reshaped\" to image format \n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "This is simply the target vector value that is associated with the image [5]\n"
     ]
    }
   ],
   "source": [
    "print('This is how X[0] looks when \"flattened\" \\n{}'.format(X[0]))\n",
    "print ('\\nThis is how X[0] looks when \"reshaped\" to image format \\n{}'.format(X[0].reshape(28,28)))\n",
    "print('\\nThis is simply the target vector value that is associated with the image {}'.format(y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c565b275",
   "metadata": {},
   "source": [
    "###  <font color='green'/> 6-TO DO:Create a subset of the digits data using only the *zeroes and ones* \n",
    "\n",
    "<font color='red'/>COMMENT: I have done this part for you but you should make sure you understand what the code does and how the subset of images is being created from the larger dataset. DO NOT ALTER THIS CODE UNLESS YOU ARE ASKED TO. **YOU MUST USE THE VARIABLE NAMES GIVEN!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02f6718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_one_indices = np.sort(np.concatenate((np.where(y == 0)[0], np.where(y == 1)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "588ea754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14780, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_one_images = X[zero_one_indices] \n",
    "zero_one_labels = y[zero_one_indices]\n",
    "zero_one_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc898a7",
   "metadata": {},
   "source": [
    "### <font color='green'/>7- TO DO:  display an image\n",
    "Display the image with index = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c4e813e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b096f22810>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 11\n",
    "plt.imshow(X[i].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db60d99",
   "metadata": {},
   "source": [
    "### <font color='green'/>8- TO DO Is the Training Dataset Balanced?\n",
    "#### <font color='blue'/> Data Visualization\n",
    "Plot a histogram (**bar chart!**) of the dataset *class labels* to make sure we have a balanaced dataset, i.e.we want to figure out how often each number is represented in the dataset. This is important when we are trying to eliminate **algorithmic bias** in our machine learning models. <font color='red'/>WARNING: Your code should be general and should be able to plot *any* two digits selected as the subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21c5c1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1b0b7323090>,\n",
       "  <matplotlib.axis.XTick at 0x1b0b7320cd0>],\n",
       " [Text(0, 0, '1'), Text(1, 0, '2')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y1 = y.flatten()\n",
    "\n",
    "digits = [1,2]  # Modify this list to select different digits\n",
    "\n",
    "# Count occurrences of each digit\n",
    "counts = np.bincount(y1)\n",
    "\n",
    "# Plot\n",
    "plt.bar(np.arange(len(digits)), counts[digits])\n",
    "plt.xticks(np.arange(len(digits)), digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5dd645",
   "metadata": {},
   "source": [
    "### <font color='green'/>9-TO DO:Split the data into Training and Testing Sets\n",
    "Scikit learn contains a function called the **train_test_split** function  that will randomly shuffle the dataset and then splits it into two datasets: a **training set** used to build the model and a **test set** to assess and evaluate how well the model works on unseen data. **Use a 75%/25% train-test split**. \n",
    "<br><br><font color='red'/>You should also use `shuffle=True` and `random_state=0` in your split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d83fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, shuffle=True)\n",
    "\n",
    "#y_train = y_train.flatten()\n",
    "#y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f94690",
   "metadata": {},
   "source": [
    "### <font color='green'/> 10- TO DO:Look at the *shape* of the data (rows and columns) *after* splitting it into training and testing sets\n",
    "**Enter your code in the next TWO cells below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d33b1742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape of the data : (52500, 784)\n",
      "y_train Shape of the data : (52500, 1)\n"
     ]
    }
   ],
   "source": [
    "print('X_train Shape of the data : {}'.format(X_train.shape))\n",
    "print('y_train Shape of the data : {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6105645c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test Shape of the data : (17500, 784)\n",
      "y_test Shape of the data : (17500, 1)\n"
     ]
    }
   ],
   "source": [
    "print('X_test Shape of the data : {}'.format(X_test.shape))\n",
    "print('y_test Shape of the data : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ab7455",
   "metadata": {},
   "source": [
    "### <font color='green'>11- TO DO: Code to plot several images</font>\n",
    "<font color='red'/>COMMENT: I have done this part for you. I have created it as a pyton callable function since we will need to use it later. You should make sure you understand what the code does and how the subset of images is being plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bc71f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(X, y):\n",
    "    \"\"\"Plot the first 5 images and their labels in a row.\"\"\"\n",
    "    plt.subplots(figsize=(9, 4))\n",
    "    for i, (img, y) in enumerate(zip(X[:5].reshape(5, 28, 28), y[:5])):\n",
    "        #subplot five images on one row\n",
    "        plt.subplot(1, 5, i+1) \n",
    "        plt.imshow(img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a45be8",
   "metadata": {},
   "source": [
    "call the function to plot a subset of images in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d11245a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_example(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f19645",
   "metadata": {},
   "source": [
    "### <font color='blue'/> Scaling the features of a dataset \n",
    "\n",
    "<h4 style=\"text-align:left; color:red\";>IMPORTANT: Standardizing the features:</h4>\n",
    "\n",
    "* There are two common approaches to bring different features onto the same scale: **normalization** and **standardization**.  Most often, normalization refers to the rescaling of the features to a range of [0, 1], which is a special case of min-max scaling. To normalize our data, we can simply apply the min-max scaling to each feature column.\n",
    "\n",
    "* Standardization of datasets (feature scaling) is a common requirement for many machine learning and optimization algorithms implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data, i.e., Gaussian with zero mean and unit variance.\n",
    "\n",
    "### <font color='green'/>12-TO DO: Scale or Noramlize the Data\n",
    "##### Use the scikit-learn  StandardScaler (MinMaxScaler) to scale (normalize) the training and testing datasets\n",
    "#### <font  color='red'/>NOTE: Create a decision structure which uses either the MinMaxScaler or the StandardScaler depending on the value of a boolean variable for normalizing or scaling the data. **SET YOUR BOOLEAN SO THAT IT STARTS WITH THE STANDARD SCALER**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf7a37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.max(), X.min()\n",
    "\n",
    "X = X/255.0\n",
    "X.max(), X.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df5a2bc",
   "metadata": {},
   "source": [
    "### <font color='green'/>13-TO DO: Build Adaptive Linear Neuron Model\n",
    "#### Instantiate the AdalineGD class train the model on the data. Use the following variable names and range of parameters:\n",
    "\n",
    "#### The Model using the Adaline Classifier:\n",
    "\n",
    "- model name  = ada\n",
    "- n_iter = you choose: must be in range 100 to 1000\n",
    "- eta = you choose: must be in range, 1.0e-4 to 1.0e-8\n",
    "- random_state = 1\n",
    "\n",
    "You can use the default values for the rest of the parameters. <font color='red'/>Your model MUST converge with accuracy > 97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate AdalineGD class\n",
    "ada = AdalineGD(n_iter=101, eta=1.0e-6, random_state=1) \n",
    "\n",
    "# Train the model on the data\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1488ddec",
   "metadata": {},
   "source": [
    "### <font color='green'/>14-TO DO: Plot the cost function versus the number of epochs\n",
    "Plot the cost function vs. the epochs (you may need to slightly modify some previous plotting code). Use appropriate labels for the axes and title. The title should say the name of the model and the learning rate being used. **Save the generated figure with the name *adaline.png***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691143df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc4817b1",
   "metadata": {},
   "source": [
    "### <font color='green'/> 15-TO DO:Model Evaluation and Performance\n",
    "\n",
    "Use the test set to create the model's predictions. Name the prediction vector **y_pred** as in previous notebooks. Make sure you display the predictions in the **y_pred** vector. Also, print the **true labels** so we can visually compare the two vectors.\n",
    "\n",
    "**Enter your code in the cell below:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6463541b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df7b808b",
   "metadata": {},
   "source": [
    "### <font color='green'/> 16-TO DO:Predict the label for a single image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0de492",
   "metadata": {},
   "source": [
    "Use class Adaline's built-in *predict method* to test the model's predictive performance for the *second* image in X_test_std. **Display the image, the predicted label and the true label**\n",
    "\n",
    "**Enter your code in the next two cells below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace55ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for prediction (COMPLETE SENTENCES!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c8a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to display predicted image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75601142",
   "metadata": {},
   "source": [
    "### <font color='green'/>17-TO DO:Print the number of misclassifications using numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de35c702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "596b125c",
   "metadata": {},
   "source": [
    "### <font color='green'/> 18-TO DO:Plot some misclassified images\n",
    "Write code for a simple decision structure such that if the misclassifications exceed five, then plot five(5) images of some of the predictions that **went wrong**. Do not rewrite the plotting code or ANY plotting code here except a call to the plotting code given in step 11. AGAIN, you MUST use the plotting code defined earlier. HINT: create an error filter using the numpy code for misclassifications and use that expression to call the plotting function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6395ac",
   "metadata": {},
   "source": [
    "```python\n",
    "#create array of true-false values\n",
    "values=[True, True, False,True, False ]\n",
    "#operate on it with np.where\n",
    "np.where(np.array(values))\n",
    "# note that this returns the indices of the True values\n",
    "#print(np.where(np.array(values)))\n",
    "\n",
    "# now look at this comparrison of operations\n",
    "np.where(np.array(values))[0] == np.array(values).nonzero()[0]\n",
    "\n",
    "# now look at this comparrison of operations\n",
    "np.where(np.array(values))[0] == np.array(values).nonzero()[0]\n",
    "\n",
    "```\n",
    "Note that these two comparisons are True! We know that `np.array(values).nonzero()` returns only values that are non-zero (True). This means that `np.where(np.array(values)` *does the same thing* as `np.array(values).nonzero()`! One takeaway is that since  `np.where(np.array(values)` has to return something  when *it* is true from the *values* that are fed into it, it rerutns the *index* of the value when the value is true. We can use this and the indices as a *filter* or *mask*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b3ce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code below for five images of misclassifications \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab66645",
   "metadata": {},
   "source": [
    "### <font color='green'/> 19-TO DO: Show the *Classification Report* for the`ada` Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ea0ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbe1404c",
   "metadata": {},
   "source": [
    "### <font color='green'/>20-TO DO: Display the *Pretty Confusion Matrix*  for the`ada` Classification Model\n",
    "<font color='red'/>NOTE: You have to provide the class labels here.Think!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f1aed0",
   "metadata": {},
   "source": [
    "## <font color='orange'/>Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f498e0e7",
   "metadata": {},
   "source": [
    "### <font color='green'/> Q1 (4 points): Using the MinMaxScaler\n",
    "\n",
    "Before you begin, enter the values from the run above where you used the `StandardScaler`. Then run the identical code *only changing to the `MinMaxScaler` for scaling the data*. <font color='red'>  If your model using `MinMaxScaler`  does not achieve an accuracury > 75% OR if it diverges, then tweak the parameters until you get > 75% accuracy.</font> Enter your results below:\n",
    "\n",
    "- misclassifications using StandarScaler = ??\n",
    "\n",
    "- misclassifications using MinMaxScaler = ??\n",
    "\n",
    "<font color='red'/> NOTE: After this question, replace the `MinMaxScaler` code with the `StandardScaler` code and use `StandardScaler` for the rest of the project. **RE-RUN YOUR CODE USING THE STANDARD SCALER.**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce54f7c",
   "metadata": {},
   "source": [
    "### <font color='green'/> Q2 (10 points): Adding an accuracy score method to your Adaline class (accuracy > 97%)\n",
    "Using **only** numpy (and of course python), modify (enhance) the class Adaline to give it a *built-in* method to return the accuracy of the trained classification mode. Your method **must** behave like scikit-learn's scoring method. That is, a user should be able to call it with code like: `ada.score(X_test_std, y_test)`. After you have modified your code, demonstrate it by calling the method with a print statement in the cell below. Record a copy of your instantiated model (showing parameters you used) in the **markdown** cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a2157",
   "metadata": {},
   "source": [
    "<font color='blue'/> Your markdown here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8779bb65",
   "metadata": {},
   "source": [
    "<font color='green'/>Copy and paste ONLY your model here (adaline StandarScaler model MUST have accuracy > 97% ):\n",
    "\n",
    "<font color='green'/>Copy and paste ONLY your model here (adaline MinMaxScaler model MUST have accuracy > 75% ):\n",
    "\n",
    "> adaline model with best performance: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d3ced",
   "metadata": {},
   "source": [
    "### <font color='green'/>Q3 (10 points)  Carefully enter the code for the Generative AI Perceptron Classification Model \n",
    "In **one** cell below, copy and enter the code from the image above to build and use to classifiy the subset of the data with the 0, 1 subset of images you used in this exam. Print the accuracy, misclassifications and the confusion matrix.\n",
    "\n",
    "<font color='red'/>Instantiate the GenAI perceptron model with thes parameters: ` learning_rate=0.0003`, `epochs = 100`, \n",
    "\n",
    "```python\n",
    "#### Example usage:\n",
    "ppnGenAI = PerceptronGenAI(input_size=X_train_std.shape[1])\n",
    "ppnGenAI.fit(X_train_std, y_train, learning_rate=0.0003, epochs=100)\n",
    "```\n",
    "## <font color = 'orange'/>class PerceptronGenAI: A GenAI Sigmoid Perceptrom model with Gradient Descent\n",
    "\n",
    "#### <font color='blue'/>Make sure you examine and undersatnd every line of code in the PerceptronGenAI  class after you enter it below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022960c9",
   "metadata": {},
   "source": [
    "<img src=\"images/class_PerceptronGenAI.svg\" width = 600; >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8053d2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f4dfc9e",
   "metadata": {},
   "source": [
    "\n",
    "<b><font color = 'orange'/> In this GenAI code:\n",
    "\n",
    "- The `sigmoid_derivative` method calculates the derivative of the sigmoid function, which is used in the gradient descent update rule.\n",
    "- In the `fit` method, the gradient descent update rule is applied to adjust the weights and bias based on the error multiplied by the derivative of the sigmoid function.\n",
    "- The learning rate controls the step size in the direction of the steepest descent in the error surface, and the number of epochs determines the number of iterations over the entire dataset for training.\n",
    "    \n",
    "<font color='red'/>Instantiate the GenAI perceptron model with these parameters: ` learning_rate=0.0003`, `epochs = 100`, \n",
    "\n",
    "```python\n",
    "#Example usage:\n",
    "ppnGenAI = PerceptronGenAI(input_size=X_train_std.shape[1])\n",
    "ppnGenAI.fit(X_train_std, y_train, learning_rate=0.0003, epochs=100)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e14cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test the trained GenAI perceptron\n",
    "for i in range(len(X_test_std)):\n",
    "    print(f\"Input: {y_test[i]}, Predicted Output: {ppnGenAI.predict(X_test_std[i]).round()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfc3371",
   "metadata": {},
   "source": [
    "## <font color='red'/>IMPORTANT:\n",
    "\n",
    "<font color='red-orange'>You will note that because we are usinng the sigmoid function in out GenAI perceptron, its output is a real number and NOT an integer. This means you MUST `round` the results!  This will be important whenever you call the `predict`method </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15394a82",
   "metadata": {},
   "source": [
    "### <font color='green'/> Q4 (5 points): Add an accuracy score method to your `GenAI` class\n",
    "Using **only** numpy (and of course python), modify (enhance) the class PerceptronGenAI to give it a *built-in* method to return the accuracy of the trained classification model. Your method **must** behave like scikit-learn's scoring method. That is, a user should be able to call it with code like: `ppnGenAI.score(X_test_std, y_test)`. After you have modified your code, demonstrate it by calling the method with a print statement in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c72787c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eae5fe01",
   "metadata": {},
   "source": [
    "### <font color='green'/> Q5 (5 points): Compute and display the misclassifications of the `GenAI` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8058ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c5f3daf",
   "metadata": {},
   "source": [
    "### <font color='green'/>Q6 (4 points) Display the Confusion Matrix for the  Generative AI  Classification Model in Q5\n",
    "Enter your code in **one** cell below: <font color='red'/><font color='red'/>WARNING:  use the GenAI name from Q3 for nameing  the prediction vector in this part to avoid future conflicts, i.e. use the name `y_pred_ppnGenAI`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cea10c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5128334d",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "## <font color='orange'/>Statistics for Evaluating the Performance of Machine Learning Models</h1>\n",
    "\n",
    "</center>\n",
    "\n",
    "We can compare two supervised machine learning models using the same training dataset by applying the classical hypothesis testing paradigm. Our measure of model performance is the test-set error rate. Below, we state the problem in the form of a *null hypothesis*.\n",
    "\n",
    ">There is no significant difference in the test set error rate of two supervised machine learning models, $M_1$ and $M_2$, built with the same training dataset.\n",
    "\n",
    "Although there are several possible test set scenarios we can use, we will take the approach that allows us to compare performance between models when:\n",
    "- *the **same** test dataset is used to compare the models, and*\n",
    "- *the comparison is is based on the overall classification correctness of the models.* \n",
    "\n",
    "While this is a simple approach, it would perhaps be more straightforward to compare model performance using **two independent testing datasets selected randomly from a a pool of sample data.** However, this approach is feasible only if there is a large supply of data available from which random test sets can be extracted. Thus, when smaller-sized datasets are all we have to work with, a single test set used on both models is probably the only possibility.\n",
    "\n",
    "\n",
    "### Comparing Models with Independent Test Data\n",
    "The simpler approach that we will take is to use a technique that compares the overall classification correctness of the models. *It shoud be noted that this method is equally valid whether we have two independent test datasets or only a single dataset to use with both models.* \n",
    "\n",
    "The most general form of the statistic for comparing the performnce of two classifier modesl  $M_1$ and $M_2$ is\n",
    "\n",
    "\\begin{eqnarray}\n",
    " P= \\frac{|E_{1} - E_{2}|}{\\sqrt{q(1-q)(1/n_{1} + 1/n_{2} )}} \n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "<div style=\"width:400px; margin:2px\">\n",
    "  \n",
    "    \n",
    "| **where:** |  |  |\n",
    "|:------|:------|:-----|\n",
    "$E_1$| is the error rate for model $M_1$| |\n",
    "|$E_2$|is the error rate for model $M_2$| |\n",
    "|$ q $| = $\\frac{(E_1 + E_2)}{2}$ is the error rate average||\n",
    "|$n_1$|is the number of instances in test set A||\n",
    "|$n_2$|is the number of instances in test set B||\n",
    "\n",
    "</div>\n",
    "<p>You should note that $q(1-q)$ is the variance score computed using the <b>average</b> of the two error rates. When we have a <em>single</em> test set of size $n$ that we use for both models, then the formula simplifies to:</p>\n",
    "\n",
    "\n",
    "\\begin{eqnarray}\n",
    " P= \\frac{|E_{1} - E_{2}|}{\\sqrt{q(1-q)(2/n )}} \n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "With either of the above equations, if, for the value of $P$ we find $P$ $\\geq$ 2, then we can be 95% confident that the difference in the test set performance is statistically significant. \n",
    "\n",
    "In this project, we shall use this simplified version of the relation since we only have one test dataset for both models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71782ce",
   "metadata": {},
   "source": [
    "### <font color='green'/>Q7 (10 points) Comparing the Performance of two Supervised Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316b228",
   "metadata": {},
   "source": [
    "### Model Performance Comparison of two Classifiers\n",
    "\n",
    "Using the **ada model** (with accuracy>90%) and the **GenAI perceptron model** (with accuracy>97%) in **Q3**, compare the performance of the models using the above statistic when we only have one test set. To do this you need to calculate (**and print**)  in each cell below, the following <font color='red'/>COMMENT: Your code must be general. you MUST use the varible names given below!:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a72ef",
   "metadata": {},
   "source": [
    "$E_1$ : the error rate for model $M_1$, your Adaline Model\n",
    "\n",
    "**Enter your code below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330f82b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60e5d784",
   "metadata": {},
   "source": [
    "$E_2$ is the error rate for model $M_2$, your Scikit-Learn Perceptron Model\n",
    "\n",
    "**Enter your code below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395ac464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c68673d8",
   "metadata": {},
   "source": [
    "$ q $ = $\\frac{(E_1 + E_2)}{2}$ ,  the error rate average\n",
    "\n",
    "**Enter your code below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2397389a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6d6151f",
   "metadata": {},
   "source": [
    "$n_1$, the number of instances in test set A\n",
    "\n",
    "**Enter your code below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a83889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f825e9df",
   "metadata": {},
   "source": [
    "$n_2$,  the number of instances in test set B\n",
    "\n",
    "**Enter your code below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02806f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d18ae04",
   "metadata": {},
   "source": [
    "#### Using Python, write a simple decision construct to compute and display $P$, depending on whether  $P$ $\\geq$ 2. Use a complete sentence in your output.\n",
    "\n",
    "**Enter your code below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c304f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e830483",
   "metadata": {},
   "source": [
    "###### <font color='purple'/>Give a brief comparative summary of the two models and your analysis in the cell below. (Keep it short! 2-4 sentences!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c7fa36",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27e0328c",
   "metadata": {},
   "source": [
    "### <font color='green'/>Q8 (6 points) Model Persistence - Save/Load the trained classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ef8caf",
   "metadata": {},
   "source": [
    "### <font color='orange'> Pickle (serialize) and save the trained *adaline* classifier to a folder. \n",
    "Enter your code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8866c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dce8535d",
   "metadata": {},
   "source": [
    "### <font color='orange'> Load the saved trained classifier into memory\n",
    "Enter your code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd397719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed7f32d7",
   "metadata": {},
   "source": [
    "### <font color='orange'> Test the re-loaded classifier\n",
    "Use the re-loaded classifier to classify an image and compare its classification to the true value.  Use an image from the normalized test set with <font color='red'>index = 25</font>. Use complete sentences in the output for the classifier's prediction such as \"The reloaded classifier predicts the image is number __\".\n",
    "    \n",
    "Enter your code in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9f28c9",
   "metadata": {},
   "source": [
    "### <font color='green'/>Q9 (6 points) Predictions with images (from Adaline)\n",
    "Use your prediction vector, y_pred, **from ada (when accuracy > 97%)** to display the first twelve(12) images and the predictions. Display these on 3 rows with 4 images per row ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c74551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "544f44e5",
   "metadata": {},
   "source": [
    "### <font color='green'/>Q10 (6 points) Predictions with images (from GenAI)\n",
    "Use your prediction vector, y_pred, **from GenAI (when accuracy > 97%)** to display the first twelve images and the predictions. Display this on 3 rows with 4 images per row ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d561eb3",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "# <font color='red'/>End of Exam!\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95a51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
